#!/usr/bin/env python3
"""
CEFR-J Wordlist Ver1.6.xlsx ã‚’è§£æã—ã¦ vocabulary_master ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®SQL INSERTæ–‡ã‚’ç”Ÿæˆ
"""

import pandas as pd
import json
import re
from pathlib import Path

# CEFR ãƒ¬ãƒ™ãƒ«ã‚’æ•°å€¤ã‚¹ã‚³ã‚¢ã«å¤‰æ›
CEFR_SCORES = {
    'A1': 1,
    'A2': 2,
    'B1': 3,
    'B2': 4,
    'C1': 5,
    'C2': 6,
    'Pre-A1': 1,
    'A1.1': 1,
    'A1.2': 1,
    'A1.3': 1,
    'A2.1': 2,
    'A2.2': 2,
    'B1.1': 3,
    'B1.2': 3,
    'B2.1': 4,
    'B2.2': 4,
}

# Eiken ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ¨å®šï¼‰
CEFR_TO_EIKEN = {
    1: 'grade_5',      # A1 â†’ è‹±æ¤œ5ç´š
    2: 'grade_4',      # A2 â†’ è‹±æ¤œ4ç´š
    3: 'pre_2',        # B1 â†’ è‹±æ¤œæº–2ç´š
    4: 'grade_2',      # B2 â†’ è‹±æ¤œ2ç´š
    5: 'pre_1',        # C1 â†’ è‹±æ¤œæº–1ç´š
    6: 'grade_1',      # C2 â†’ è‹±æ¤œ1ç´š
}

def normalize_cefr_level(level_str):
    """CEFR ãƒ¬ãƒ™ãƒ«æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–"""
    if not level_str or pd.isna(level_str):
        return None
    
    level_str = str(level_str).strip().upper()
    
    # Pre-A1, A1.1 ãªã©ã‚’ A1 ã«æ­£è¦åŒ–
    if level_str.startswith('PRE-'):
        return 'A1'
    if '.' in level_str:
        return level_str.split('.')[0]
    
    return level_str if level_str in ['A1', 'A2', 'B1', 'B2', 'C1', 'C2'] else None

def calculate_difficulty_score(cefr_level, frequency=None):
    """
    é›£æ˜“åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®— (0-100)
    CEFR ãƒ¬ãƒ™ãƒ«ã¨é »åº¦ã«åŸºã¥ã
    """
    if not cefr_level:
        return 50  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    cefr_score = CEFR_SCORES.get(cefr_level, 3)
    
    # CEFR ã‚¹ã‚³ã‚¢ã‚’ 0-100 ã«å¤‰æ›
    # A1=20, A2=35, B1=50, B2=65, C1=80, C2=95
    base_score = 15 + (cefr_score * 15)
    
    # é »åº¦ã§å¾®èª¿æ•´ï¼ˆã‚‚ã—åˆ©ç”¨å¯èƒ½ãªã‚‰ï¼‰
    if frequency and not pd.isna(frequency):
        try:
            freq_value = float(frequency)
            # é«˜é »åº¦ = ä½é›£æ˜“åº¦
            if freq_value > 1000:
                base_score -= 5
            elif freq_value < 100:
                base_score += 5
        except:
            pass
    
    return min(100, max(0, base_score))

def parse_wordlist(excel_path):
    """Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦èªå½™ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    print(f"ğŸ“– Reading Excel file: {excel_path}")
    
    # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    xl = pd.ExcelFile(excel_path)
    print(f"ğŸ“‹ Sheets found: {xl.sheet_names}")
    
    # 'ALL' ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ï¼ˆã™ã¹ã¦ã®èªå½™ãŒå«ã¾ã‚Œã‚‹ï¼‰
    df = pd.read_excel(excel_path, sheet_name='ALL')
    print(f"ğŸ“Š Total rows: {len(df)}")
    print(f"ğŸ“Š Columns: {df.columns.tolist()}")
    
    # æœ€åˆã®æ•°è¡Œã‚’è¡¨ç¤º
    print("\nğŸ“ First 5 rows:")
    print(df.head())
    
    vocabulary_data = []
    
    for idx, row in df.iterrows():
        # å˜èªã¨ãƒ¬ãƒ™ãƒ«ã®åˆ—ã‚’æ¢ã™ï¼ˆåˆ—åã¯å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
        word = None
        cefr_level = None
        pos = None
        
        # åˆ—åã‚’ç¢ºèªã—ã¦é©åˆ‡ã«å‰²ã‚Šå½“ã¦
        for col in df.columns:
            col_lower = str(col).lower()
            if 'word' in col_lower or 'lemma' in col_lower:
                word = row[col]
            elif 'cefr' in col_lower or 'level' in col_lower:
                cefr_level = row[col]
            elif 'pos' in col_lower or 'part' in col_lower:
                pos = row[col]
        
        if not word or pd.isna(word):
            continue
        
        word = str(word).strip().lower()
        
        # CEFR ãƒ¬ãƒ™ãƒ«ã‚’æ­£è¦åŒ–
        normalized_cefr = normalize_cefr_level(cefr_level)
        if not normalized_cefr:
            continue
        
        cefr_score = CEFR_SCORES.get(normalized_cefr, 3)
        difficulty = calculate_difficulty_score(normalized_cefr)
        eiken_grade = CEFR_TO_EIKEN.get(cefr_score, 'pre_2')
        
        # å“è©ã‚’æ­£è¦åŒ–
        if pos and not pd.isna(pos):
            pos_str = str(pos).strip().lower()
        else:
            pos_str = 'unknown'
        
        vocab_entry = {
            'word': word,
            'part_of_speech': pos_str,
            'cefr_level': normalized_cefr,
            'cefr_score': cefr_score,
            'difficulty_score': difficulty,
            'eiken_grade': eiken_grade,
            'frequency_rank': idx + 1,  # è¡Œç•ªå·ã‚’é »åº¦ãƒ©ãƒ³ã‚¯ã¨ã—ã¦ä½¿ç”¨
        }
        
        vocabulary_data.append(vocab_entry)
    
    print(f"\nâœ… Parsed {len(vocabulary_data)} vocabulary entries")
    
    # ãƒ¬ãƒ™ãƒ«åˆ¥ã®çµ±è¨ˆ
    level_counts = {}
    for entry in vocabulary_data:
        level = entry['cefr_level']
        level_counts[level] = level_counts.get(level, 0) + 1
    
    print("\nğŸ“Š Vocabulary distribution by CEFR level:")
    for level in sorted(level_counts.keys()):
        print(f"  {level}: {level_counts[level]} words")
    
    return vocabulary_data

def generate_sql_inserts(vocabulary_data, output_file):
    """SQL INSERT æ–‡ã‚’ç”Ÿæˆ"""
    print(f"\nğŸ“ Generating SQL INSERT statements...")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("-- CEFR-J Wordlist Ver1.6 - Vocabulary Import\n")
        f.write("-- Generated from CEFR-J_Wordlist_Ver1.6.xlsx\n\n")
        
        # ãƒãƒƒãƒæŒ¿å…¥ï¼ˆ500å˜èªãšã¤ï¼‰
        batch_size = 500
        for i in range(0, len(vocabulary_data), batch_size):
            batch = vocabulary_data[i:i+batch_size]
            
            f.write(f"-- Batch {i//batch_size + 1}: Words {i+1} to {min(i+batch_size, len(vocabulary_data))}\n")
            f.write("INSERT OR IGNORE INTO vocabulary_master (\n")
            f.write("  word, pos, definition_en, definition_ja,\n")
            f.write("  cefr_level, cefr_score, frequency_rank, final_difficulty_score,\n")
            f.write("  eiken_grade, should_annotate, created_at\n")
            f.write(") VALUES\n")
            
            values = []
            for entry in batch:
                word = entry['word'].replace("'", "''")
                pos = entry['part_of_speech'].replace("'", "''")
                cefr_level = entry['cefr_level']
                cefr_score = entry['cefr_score']
                freq_rank = entry['frequency_rank']
                difficulty = entry['difficulty_score']
                eiken_grade = entry['eiken_grade']
                
                # é›£æ˜“åº¦40ä»¥ä¸Šã¯ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¯¾è±¡
                should_annotate = 1 if difficulty >= 40 else 0
                
                value_str = (
                    f"  ('{word}', '{pos}', '', '', "
                    f"'{cefr_level}', {cefr_score}, {freq_rank}, {difficulty}, "
                    f"'{eiken_grade}', {should_annotate}, CURRENT_TIMESTAMP)"
                )
                values.append(value_str)
            
            f.write(",\n".join(values))
            f.write(";\n\n")
    
    print(f"âœ… SQL file generated: {output_file}")
    print(f"ğŸ“Š Total INSERT statements: {len(vocabulary_data)} words")

def main():
    excel_file = Path("/home/user/webapp/CEFR-J_Wordlist_Ver1.6.xlsx")
    output_file = Path("/home/user/webapp/migrations/0019_import_cefrj_wordlist.sql")
    
    if not excel_file.exists():
        print(f"âŒ Error: File not found: {excel_file}")
        return
    
    # Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
    vocabulary_data = parse_wordlist(excel_file)
    
    if not vocabulary_data:
        print("âŒ No vocabulary data extracted!")
        return
    
    # SQL INSERT æ–‡ã‚’ç”Ÿæˆ
    generate_sql_inserts(vocabulary_data, output_file)
    
    print("\nğŸ‰ Import script completed successfully!")
    print(f"ğŸ“‚ SQL file: {output_file}")
    print("\nğŸš€ Next step: Apply migration with:")
    print(f"   npx wrangler d1 execute kobeya-logs-db --local --file={output_file}")

if __name__ == "__main__":
    main()
