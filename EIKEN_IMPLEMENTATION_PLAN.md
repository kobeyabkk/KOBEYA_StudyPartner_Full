# è‹±æ¤œAIå•é¡Œç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  - æœ€çµ‚å®Ÿè£…è¨ˆç”»æ›¸

## ğŸ“Š 3ã¤ã®AIã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®åˆ†æçµæœ

### å…±é€šã™ã‚‹æ¨å¥¨äº‹é …ï¼ˆå…¨å“¡ä¸€è‡´ï¼‰

1. **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ**: Option D (ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–) + Few-shot Learning
2. **èªå½™æ¤œè¨¼**: æ–¹å¼A (D1ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢) + æ´»ç”¨å½¢å¯¾å¿œ
3. **æ–‡æ³•åˆ¶å¾¡**: Few-shot Examples + ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒªã‚¹ãƒˆ
4. **ã‚³ã‚¹ãƒˆæœ€é©åŒ–**: gpt-4o-miniå„ªå…ˆ + Prompt Caching
5. **å®Ÿè£…é †åº**: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆï¼ˆèªå½™DBæ§‹ç¯‰ãŒæœ€å„ªå…ˆï¼‰

### é‡è¦ãªç‹¬è‡ªææ¡ˆ

#### ChatGPTã®ææ¡ˆ
- **è»½é‡ãƒ¬ãƒåŒ–**: è¦å‰‡ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“lemmatizationï¼ˆWorkersé©åˆï¼‰
- **KVã‚­ãƒ£ãƒƒã‚·ãƒ¥**: èªå½™æ¤œè¨¼çµæœã‚’24æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
- **è‡ªå‹•ãƒªãƒ©ã‚¤ãƒˆ**: é•åèªã®ã¿ã‚’gpt-4o-miniã§ç½®æ›

#### GenSparkã®ææ¡ˆ
- **ãƒãƒƒãƒç”Ÿæˆ**: 10å•ã¾ã¨ã‚ã¦ç”Ÿæˆã—ã¦ã‚³ã‚¹ãƒˆå‰Šæ¸›
- **äºŒè»¸æ¤œè¨¼**: CEFR level + Zipfé »åº¦ã‚¹ã‚³ã‚¢ã®ä½µç”¨
- **ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥**: miniå¤±æ•—æ™‚ã®ã¿gpt-4oä½¿ç”¨

#### Geminiã®ææ¡ˆ
- **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†**: æ´»ç”¨å½¢å±•é–‹ã‚’ãƒãƒƒãƒã§äº‹å‰å®Ÿè¡Œ
- **Cron Trigger**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨AIç”Ÿæˆã‚’å®Œå…¨åˆ†é›¢
- **éåŒæœŸç”Ÿæˆ**: æ‰¿èªæ¸ˆã¿å•é¡Œãƒ—ãƒ¼ãƒ«ã‹ã‚‰å³åº§ã«è¿”ç­”

---

## ğŸ¯ æ¡ç”¨ã™ã‚‹æœ€çµ‚æˆ¦ç•¥

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ãƒ¦ãƒ¼ã‚¶ãƒ¼API                            â”‚
â”‚  GET /api/eiken/generate?grade=5&section=vocabulary     â”‚
â”‚  â†’ D1ã‹ã‚‰æ‰¿èªæ¸ˆã¿å•é¡Œã‚’å³åº§ã«è¿”ç­”ï¼ˆ10-50msï¼‰              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–²
                             â”‚ æ‰¿èªæ¸ˆã¿å•é¡Œã‚’æ ¼ç´
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Cron Trigger Workerï¼ˆ10åˆ†æ¯ï¼‰               â”‚
â”‚  1. gpt-4o-miniã§å•é¡Œç”Ÿæˆï¼ˆãƒãƒƒãƒ10å•ï¼‰                   â”‚
â”‚  2. èªå½™ãƒ»æ–‡æ³•æ¤œè¨¼ï¼ˆD1 + KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰                    â”‚
â”‚  3. é•åã‚ã‚Šâ†’è‡ªå‹•ãƒªãƒ©ã‚¤ãƒˆï¼ˆminiï¼‰                         â”‚
â”‚  4. ãƒªãƒ©ã‚¤ãƒˆå¤±æ•—â†’gpt-4oã§ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³                 â”‚
â”‚  5. æ‰¿èªæ¸ˆã¿å•é¡Œã‚’D1ã«ä¿å­˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    D1 Database                           â”‚
â”‚  - eiken_vocabulary_lexicon (æ´»ç”¨å½¢å±•é–‹æ¸ˆã¿100ä¸‡èª)       â”‚
â”‚  - eiken_generated_questions (æ‰¿èªæ¸ˆã¿å•é¡Œãƒ—ãƒ¼ãƒ«)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆWeek-by-Weekï¼‰

### Week 1: ãƒ‡ãƒ¼ã‚¿åŸºç›¤æ§‹ç¯‰

#### Day 1-2: CEFR-Jèªå½™ã®æ´»ç”¨å½¢å±•é–‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**ç›®æ¨™**: 25ä¸‡èª â†’ 100ä¸‡èªï¼ˆæ´»ç”¨å½¢å«ã‚€ï¼‰

```typescript
// scripts/expand-vocabulary.ts

interface VocabEntry {
  word: string;
  pos: string;      // å“è©
  cefr_level: string;
  frequency_rank?: number;
  topic_category?: string;
}

interface ExpandedEntry extends VocabEntry {
  lemma: string;    // åŸå½¢
  inflection?: string; // æ´»ç”¨ã®ç¨®é¡
}

class VocabularyExpander {
  // å‹•è©æ´»ç”¨è¦å‰‡
  private expandVerb(base: string): ExpandedEntry[] {
    const results: ExpandedEntry[] = [];
    
    // åŸå½¢
    results.push({ word: base, lemma: base, pos: 'verb' });
    
    // ä¸‰äººç§°å˜æ•°
    if (base.endsWith('s') || base.endsWith('sh') || base.endsWith('ch') || 
        base.endsWith('x') || base.endsWith('o')) {
      results.push({ word: base + 'es', lemma: base, pos: 'verb', inflection: '3sg' });
    } else if (base.endsWith('y') && !this.isVowel(base[base.length - 2])) {
      results.push({ word: base.slice(0, -1) + 'ies', lemma: base, pos: 'verb', inflection: '3sg' });
    } else {
      results.push({ word: base + 's', lemma: base, pos: 'verb', inflection: '3sg' });
    }
    
    // é€²è¡Œå½¢
    if (this.shouldDoubleConsonant(base)) {
      results.push({ word: base + base[base.length - 1] + 'ing', lemma: base, pos: 'verb', inflection: 'gerund' });
    } else if (base.endsWith('e') && base.length > 2) {
      results.push({ word: base.slice(0, -1) + 'ing', lemma: base, pos: 'verb', inflection: 'gerund' });
    } else {
      results.push({ word: base + 'ing', lemma: base, pos: 'verb', inflection: 'gerund' });
    }
    
    // éå»å½¢ãƒ»éå»åˆ†è©ï¼ˆè¦å‰‡å‹•è©ï¼‰
    if (base.endsWith('e')) {
      results.push({ word: base + 'd', lemma: base, pos: 'verb', inflection: 'past' });
    } else if (base.endsWith('y') && !this.isVowel(base[base.length - 2])) {
      results.push({ word: base.slice(0, -1) + 'ied', lemma: base, pos: 'verb', inflection: 'past' });
    } else if (this.shouldDoubleConsonant(base)) {
      results.push({ word: base + base[base.length - 1] + 'ed', lemma: base, pos: 'verb', inflection: 'past' });
    } else {
      results.push({ word: base + 'ed', lemma: base, pos: 'verb', inflection: 'past' });
    }
    
    return results;
  }
  
  // ä¸è¦å‰‡å‹•è©ãƒãƒƒãƒ”ãƒ³ã‚°
  private readonly irregularVerbs: Record<string, string[]> = {
    'be': ['am', 'is', 'are', 'was', 'were', 'been', 'being'],
    'have': ['has', 'had', 'having'],
    'do': ['does', 'did', 'done', 'doing'],
    'go': ['goes', 'went', 'gone', 'going'],
    'eat': ['eats', 'ate', 'eaten', 'eating'],
    'drink': ['drinks', 'drank', 'drunk', 'drinking'],
    'see': ['sees', 'saw', 'seen', 'seeing'],
    'come': ['comes', 'came', 'coming'],
    'take': ['takes', 'took', 'taken', 'taking'],
    'get': ['gets', 'got', 'gotten', 'getting'],
    'make': ['makes', 'made', 'making'],
    'know': ['knows', 'knew', 'known', 'knowing'],
    'think': ['thinks', 'thought', 'thinking'],
    'say': ['says', 'said', 'saying'],
    'find': ['finds', 'found', 'finding'],
    'give': ['gives', 'gave', 'given', 'giving'],
    'tell': ['tells', 'told', 'telling'],
    'become': ['becomes', 'became', 'becoming'],
    'leave': ['leaves', 'left', 'leaving'],
    'feel': ['feels', 'felt', 'feeling'],
    'bring': ['brings', 'brought', 'bringing'],
    'begin': ['begins', 'began', 'begun', 'beginning'],
    'keep': ['keeps', 'kept', 'keeping'],
    'hold': ['holds', 'held', 'holding'],
    'write': ['writes', 'wrote', 'written', 'writing'],
    'stand': ['stands', 'stood', 'standing'],
    'hear': ['hears', 'heard', 'hearing'],
    'let': ['lets', 'letting'],
    'mean': ['means', 'meant', 'meaning'],
    'set': ['sets', 'setting'],
    'meet': ['meets', 'met', 'meeting'],
    'run': ['runs', 'ran', 'running'],
    'pay': ['pays', 'paid', 'paying'],
    'sit': ['sits', 'sat', 'sitting'],
    'speak': ['speaks', 'spoke', 'spoken', 'speaking'],
    'lie': ['lies', 'lay', 'lain', 'lying'],
    'lead': ['leads', 'led', 'leading'],
    'read': ['reads', 'reading'], // éå»å½¢ã‚‚'read'ã ãŒç™ºéŸ³ç•°ãªã‚‹
    'grow': ['grows', 'grew', 'grown', 'growing'],
    'lose': ['loses', 'lost', 'losing'],
    'fall': ['falls', 'fell', 'fallen', 'falling'],
    'send': ['sends', 'sent', 'sending'],
    'build': ['builds', 'built', 'building'],
    'understand': ['understands', 'understood', 'understanding'],
    'draw': ['draws', 'drew', 'drawn', 'drawing'],
    'break': ['breaks', 'broke', 'broken', 'breaking'],
    'spend': ['spends', 'spent', 'spending'],
    'cut': ['cuts', 'cutting'],
    'rise': ['rises', 'rose', 'risen', 'rising'],
    'drive': ['drives', 'drove', 'driven', 'driving'],
    'buy': ['buys', 'bought', 'buying'],
    'wear': ['wears', 'wore', 'worn', 'wearing'],
    'choose': ['chooses', 'chose', 'chosen', 'choosing'],
    'seek': ['seeks', 'sought', 'seeking'],
    'throw': ['throws', 'threw', 'thrown', 'throwing'],
    'catch': ['catches', 'caught', 'catching'],
    'deal': ['deals', 'dealt', 'dealing'],
    'win': ['wins', 'won', 'winning'],
    'forget': ['forgets', 'forgot', 'forgotten', 'forgetting'],
    'sell': ['sells', 'sold', 'selling'],
    'fight': ['fights', 'fought', 'fighting'],
    'teach': ['teaches', 'taught', 'teaching'],
    'fly': ['flies', 'flew', 'flown', 'flying'],
    'sleep': ['sleeps', 'slept', 'sleeping'],
    'sing': ['sings', 'sang', 'sung', 'singing']
  };
  
  // åè©è¤‡æ•°å½¢
  private expandNoun(base: string): ExpandedEntry[] {
    const results: ExpandedEntry[] = [];
    
    results.push({ word: base, lemma: base, pos: 'noun', inflection: 'singular' });
    
    // è¤‡æ•°å½¢
    if (base.endsWith('s') || base.endsWith('ss') || base.endsWith('sh') || 
        base.endsWith('ch') || base.endsWith('x') || base.endsWith('o')) {
      results.push({ word: base + 'es', lemma: base, pos: 'noun', inflection: 'plural' });
    } else if (base.endsWith('y') && !this.isVowel(base[base.length - 2])) {
      results.push({ word: base.slice(0, -1) + 'ies', lemma: base, pos: 'noun', inflection: 'plural' });
    } else if (base.endsWith('f')) {
      results.push({ word: base.slice(0, -1) + 'ves', lemma: base, pos: 'noun', inflection: 'plural' });
    } else if (base.endsWith('fe')) {
      results.push({ word: base.slice(0, -2) + 'ves', lemma: base, pos: 'noun', inflection: 'plural' });
    } else {
      results.push({ word: base + 's', lemma: base, pos: 'noun', inflection: 'plural' });
    }
    
    return results;
  }
  
  // ä¸è¦å‰‡åè©
  private readonly irregularNouns: Record<string, string> = {
    'child': 'children',
    'person': 'people',
    'man': 'men',
    'woman': 'women',
    'tooth': 'teeth',
    'foot': 'feet',
    'mouse': 'mice',
    'goose': 'geese',
    'ox': 'oxen',
    'sheep': 'sheep',
    'deer': 'deer',
    'fish': 'fish'
  };
  
  // å½¢å®¹è©æ¯”è¼ƒç´šãƒ»æœ€ä¸Šç´š
  private expandAdjective(base: string): ExpandedEntry[] {
    const results: ExpandedEntry[] = [];
    
    results.push({ word: base, lemma: base, pos: 'adjective', inflection: 'positive' });
    
    // 1éŸ³ç¯€ã¾ãŸã¯2éŸ³ç¯€ï¼ˆ-yçµ‚ã‚ã‚Šï¼‰
    if (base.length <= 4 || base.endsWith('y')) {
      if (base.endsWith('e')) {
        results.push({ word: base + 'r', lemma: base, pos: 'adjective', inflection: 'comparative' });
        results.push({ word: base + 'st', lemma: base, pos: 'adjective', inflection: 'superlative' });
      } else if (base.endsWith('y')) {
        results.push({ word: base.slice(0, -1) + 'ier', lemma: base, pos: 'adjective', inflection: 'comparative' });
        results.push({ word: base.slice(0, -1) + 'iest', lemma: base, pos: 'adjective', inflection: 'superlative' });
      } else if (this.shouldDoubleConsonant(base)) {
        results.push({ word: base + base[base.length - 1] + 'er', lemma: base, pos: 'adjective', inflection: 'comparative' });
        results.push({ word: base + base[base.length - 1] + 'est', lemma: base, pos: 'adjective', inflection: 'superlative' });
      } else {
        results.push({ word: base + 'er', lemma: base, pos: 'adjective', inflection: 'comparative' });
        results.push({ word: base + 'est', lemma: base, pos: 'adjective', inflection: 'superlative' });
      }
    }
    
    return results;
  }
  
  // ä¸è¦å‰‡å½¢å®¹è©
  private readonly irregularAdjectives: Record<string, string[]> = {
    'good': ['better', 'best'],
    'bad': ['worse', 'worst'],
    'little': ['less', 'least'],
    'much': ['more', 'most'],
    'many': ['more', 'most'],
    'far': ['farther', 'farthest', 'further', 'furthest']
  };
  
  private isVowel(char: string): boolean {
    return ['a', 'e', 'i', 'o', 'u'].includes(char?.toLowerCase());
  }
  
  private shouldDoubleConsonant(word: string): boolean {
    if (word.length < 3) return false;
    const last = word[word.length - 1];
    const secondLast = word[word.length - 2];
    const thirdLast = word[word.length - 3];
    
    return !this.isVowel(last) && 
           this.isVowel(secondLast) && 
           !this.isVowel(thirdLast) &&
           !['w', 'x', 'y'].includes(last);
  }
  
  async expandAndSave(
    inputCsv: string,
    db: D1Database
  ): Promise<void> {
    // 1. CEFR-J Wordlistã‚’èª­ã¿è¾¼ã¿
    const entries: VocabEntry[] = await this.parseCsv(inputCsv);
    
    // 2. å„å˜èªã‚’å±•é–‹
    const expanded: ExpandedEntry[] = [];
    
    for (const entry of entries) {
      if (entry.pos === 'verb') {
        // ä¸è¦å‰‡å‹•è©ãƒã‚§ãƒƒã‚¯
        if (this.irregularVerbs[entry.word]) {
          expanded.push({ ...entry, lemma: entry.word });
          for (const form of this.irregularVerbs[entry.word]) {
            expanded.push({ 
              ...entry, 
              word: form, 
              lemma: entry.word,
              inflection: 'irregular'
            });
          }
        } else {
          expanded.push(...this.expandVerb(entry.word).map(e => ({ ...entry, ...e })));
        }
      } else if (entry.pos === 'noun') {
        // ä¸è¦å‰‡åè©ãƒã‚§ãƒƒã‚¯
        if (this.irregularNouns[entry.word]) {
          expanded.push({ ...entry, lemma: entry.word, inflection: 'singular' });
          expanded.push({ 
            ...entry, 
            word: this.irregularNouns[entry.word],
            lemma: entry.word,
            inflection: 'plural'
          });
        } else {
          expanded.push(...this.expandNoun(entry.word).map(e => ({ ...entry, ...e })));
        }
      } else if (entry.pos === 'adjective') {
        // ä¸è¦å‰‡å½¢å®¹è©ãƒã‚§ãƒƒã‚¯
        if (this.irregularAdjectives[entry.word]) {
          expanded.push({ ...entry, lemma: entry.word, inflection: 'positive' });
          const [comp, superl] = this.irregularAdjectives[entry.word];
          expanded.push({ 
            ...entry, 
            word: comp,
            lemma: entry.word,
            inflection: 'comparative'
          });
          if (superl) {
            expanded.push({ 
              ...entry, 
              word: superl,
              lemma: entry.word,
              inflection: 'superlative'
            });
          }
        } else {
          expanded.push(...this.expandAdjective(entry.word).map(e => ({ ...entry, ...e })));
        }
      } else {
        // ãã®ä»–ã®å“è©ã¯åŸå½¢ã®ã¿
        expanded.push({ ...entry, lemma: entry.word });
      }
    }
    
    // 3. D1ã«ãƒãƒƒãƒã‚¤ãƒ³ã‚µãƒ¼ãƒˆ
    const stmt = db.prepare(`
      INSERT OR REPLACE INTO eiken_vocabulary_lexicon 
      (word, lemma, pos, cefr_level, frequency_rank, topic_category, inflection)
      VALUES (?, ?, ?, ?, ?, ?, ?)
    `);
    
    const batches = [];
    for (const entry of expanded) {
      batches.push(
        stmt.bind(
          entry.word.toLowerCase(),
          entry.lemma.toLowerCase(),
          entry.pos,
          entry.cefr_level,
          entry.frequency_rank || null,
          entry.topic_category || null,
          entry.inflection || null
        )
      );
    }
    
    // D1ã®batchã¯500ä»¶ã¾ã§
    for (let i = 0; i < batches.length; i += 500) {
      await db.batch(batches.slice(i, i + 500));
    }
    
    console.log(`âœ… Expanded ${entries.length} entries to ${expanded.length} forms`);
  }
  
  private async parseCsv(path: string): Promise<VocabEntry[]> {
    // CSV parsing logic here
    return [];
  }
}
```

#### Day 3-4: D1ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆã¨æœ€é©åŒ–

```sql
-- eiken_vocabulary_lexicon ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
CREATE TABLE IF NOT EXISTS eiken_vocabulary_lexicon (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  word TEXT NOT NULL,                -- æ´»ç”¨å½¢ã‚’å«ã‚€å®Ÿéš›ã®å˜èª
  lemma TEXT NOT NULL,               -- åŸå½¢ï¼ˆè¦‹å‡ºã—èªï¼‰
  pos TEXT NOT NULL,                 -- å“è©
  cefr_level TEXT NOT NULL,          -- A1, A2, B1, B2, C1, C2
  grade_equivalent TEXT,             -- è‹±æ¤œç´šï¼ˆ5, 4, 3, pre-2, 2, pre-1, 1ï¼‰
  frequency_rank INTEGER,            -- é »åº¦ãƒ©ãƒ³ã‚¯ï¼ˆå°ã•ã„ã»ã©é »å‡ºï¼‰
  zipf_score REAL,                   -- Zipfã‚¹ã‚³ã‚¢ï¼ˆ1.0-7.0ï¼‰
  topic_category TEXT,               -- ãƒˆãƒ”ãƒƒã‚¯ã‚«ãƒ†ã‚´ãƒªãƒ¼
  inflection TEXT,                   -- æ´»ç”¨ã®ç¨®é¡ï¼ˆ3sg, past, pluralç­‰ï¼‰
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  UNIQUE(word, pos)                  -- åŒã˜å˜èªã§ã‚‚å“è©ãŒé•ãˆã°åˆ¥ã‚¨ãƒ³ãƒˆãƒªãƒ¼
);

-- é«˜é€Ÿæ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE UNIQUE INDEX IF NOT EXISTS idx_word_pos ON eiken_vocabulary_lexicon(word, pos);
CREATE INDEX IF NOT EXISTS idx_lemma ON eiken_vocabulary_lexicon(lemma);
CREATE INDEX IF NOT EXISTS idx_cefr_level ON eiken_vocabulary_lexicon(cefr_level);
CREATE INDEX IF NOT EXISTS idx_grade ON eiken_vocabulary_lexicon(grade_equivalent);

-- eiken_generated_questions ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
CREATE TABLE IF NOT EXISTS eiken_generated_questions (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  grade TEXT NOT NULL,
  section TEXT NOT NULL,
  question_type TEXT NOT NULL,
  answer_type TEXT DEFAULT 'mcq',
  question_text TEXT NOT NULL,
  choices_json TEXT,                 -- JSONé…åˆ—
  correct_answer_index INTEGER,
  explanation TEXT,
  explanation_ja TEXT,               -- æ—¥æœ¬èªè§£èª¬
  translation_ja TEXT,               -- å•é¡Œæ–‡ã®æ—¥æœ¬èªè¨³
  difficulty_score REAL,
  
  -- æ¤œè¨¼çµæœ
  vocab_validation_passed INTEGER DEFAULT 0,
  vocab_violation_ratio REAL,
  vocab_violations_json TEXT,        -- é•åèªã®ãƒªã‚¹ãƒˆ
  grammar_validation_passed INTEGER DEFAULT 0,
  grammar_violations_json TEXT,
  
  -- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç®¡ç†
  review_status TEXT DEFAULT 'pending', -- pending, approved, rejected
  generation_attempt INTEGER DEFAULT 1,
  model_used TEXT,                   -- gpt-4o-mini, gpt-4o
  
  -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
  similarity_score REAL,
  copyright_safe INTEGER DEFAULT 1,
  generated_at TIMESTAMP,
  reviewed_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX IF NOT EXISTS idx_grade_section_status 
  ON eiken_generated_questions(grade, section, review_status);
CREATE INDEX IF NOT EXISTS idx_review_status 
  ON eiken_generated_questions(review_status);
```

#### Day 5-7: èªå½™æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…

```typescript
// src/eiken/services/vocabulary-validator.ts

interface ValidationResult {
  passed: boolean;
  violationRatio: number;
  violations: VocabViolation[];
  stats: {
    totalWords: number;
    uniqueWords: number;
    knownWords: number;
    unknownWords: number;
  };
}

interface VocabViolation {
  word: string;
  lemma?: string;
  actualLevel: string;
  targetLevel: string;
  zipfScore?: number;
}

export class VocabularyValidator {
  private db: D1Database;
  private kv?: KVNamespace; // ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ï¼‰
  
  constructor(db: D1Database, kv?: KVNamespace) {
    this.db = db;
    this.kv = kv;
  }
  
  async validate(
    text: string,
    targetGrade: string,
    options: {
      strictMode?: boolean;      // true = 0%é•åè¨±å®¹, false = 5%é•åè¨±å®¹
      useZipf?: boolean;          // Zipfã‚¹ã‚³ã‚¢ã‚‚è€ƒæ…®
      cacheDuration?: number;     // KVã‚­ãƒ£ãƒƒã‚·ãƒ¥æœŸé–“ï¼ˆç§’ï¼‰
    } = {}
  ): Promise<ValidationResult> {
    const { 
      strictMode = false, 
      useZipf = true,
      cacheDuration = 86400  // 24æ™‚é–“
    } = options;
    
    // 1. ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
    const tokens = this.tokenize(text);
    const uniqueTokens = Array.from(new Set(tokens));
    
    // 2. KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    if (this.kv && cacheDuration > 0) {
      const cacheKey = `vocab:${targetGrade}:${uniqueTokens.sort().join(',')}`;
      const cached = await this.kv.get(cacheKey, 'json');
      if (cached) {
        return cached as ValidationResult;
      }
    }
    
    // 3. D1ã§ä¸€æ‹¬æ¤œç´¢ï¼ˆ500ä»¶ãšã¤ãƒãƒ£ãƒ³ã‚¯ï¼‰
    const chunks = this.chunkArray(uniqueTokens, 500);
    const allResults: Map<string, any> = new Map();
    
    for (const chunk of chunks) {
      const placeholders = chunk.map(() => '?').join(',');
      const result = await this.db.prepare(`
        SELECT word, lemma, pos, cefr_level, zipf_score
        FROM eiken_vocabulary_lexicon
        WHERE word IN (${placeholders})
      `).bind(...chunk).all();
      
      for (const row of result.results) {
        allResults.set(row.word as string, row);
      }
    }
    
    // 4. ãƒ¬ãƒ™ãƒ«åˆ¤å®š
    const targetCefr = this.gradeToCefr(targetGrade);
    const violations: VocabViolation[] = [];
    const knownWords: string[] = [];
    const unknownWords: string[] = [];
    
    for (const token of uniqueTokens) {
      const entry = allResults.get(token);
      
      if (!entry) {
        // æ©Ÿèƒ½èªï¼ˆa, the, Iç­‰ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
        if (this.isFunctionWord(token)) {
          knownWords.push(token);
          continue;
        }
        unknownWords.push(token);
        continue;
      }
      
      knownWords.push(token);
      
      // CEFRãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯
      const isLevelOk = this.isLevelAllowed(entry.cefr_level, targetCefr);
      
      // Zipfã‚¹ã‚³ã‚¢ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
      const isZipfOk = !useZipf || 
        !entry.zipf_score || 
        entry.zipf_score >= this.getMinZipf(targetGrade);
      
      if (!isLevelOk || !isZipfOk) {
        violations.push({
          word: token,
          lemma: entry.lemma,
          actualLevel: entry.cefr_level,
          targetLevel: targetCefr,
          zipfScore: entry.zipf_score
        });
      }
    }
    
    // 5. åˆæ ¼åˆ¤å®š
    const violationRatio = violations.length / uniqueTokens.length;
    const threshold = strictMode ? 0.0 : 0.05; // 5%è¨±å®¹
    
    const result: ValidationResult = {
      passed: violationRatio <= threshold && unknownWords.length === 0,
      violationRatio,
      violations,
      stats: {
        totalWords: tokens.length,
        uniqueWords: uniqueTokens.length,
        knownWords: knownWords.length,
        unknownWords: unknownWords.length
      }
    };
    
    // 6. KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    if (this.kv && cacheDuration > 0) {
      const cacheKey = `vocab:${targetGrade}:${uniqueTokens.sort().join(',')}`;
      await this.kv.put(cacheKey, JSON.stringify(result), { expirationTtl: cacheDuration });
    }
    
    return result;
  }
  
  private tokenize(text: string): string[] {
    return text
      .toLowerCase()
      .replace(/['']/g, "'")     // ã‚¹ãƒãƒ¼ãƒˆã‚¯ã‚ªãƒ¼ãƒˆæ­£è¦åŒ–
      .replace(/[""]/g, '"')
      .replace(/[^\w\s'-]/g, ' ') // è¨˜å·é™¤å»
      .split(/\s+/)
      .filter(w => w.length > 0);
  }
  
  private isFunctionWord(word: string): boolean {
    const functionWords = new Set([
      'a', 'an', 'the',
      'i', 'you', 'he', 'she', 'it', 'we', 'they',
      'my', 'your', 'his', 'her', 'its', 'our', 'their',
      'me', 'him', 'her', 'us', 'them',
      'this', 'that', 'these', 'those',
      'in', 'on', 'at', 'to', 'for', 'with', 'from', 'by', 'about',
      'and', 'or', 'but', 'so', 'because', 'if', 'when',
      'is', 'am', 'are', 'was', 'were', 'be', 'been', 'being',
      'do', 'does', 'did', 'done', 'doing',
      'have', 'has', 'had', 'having',
      'will', 'would', 'can', 'could', 'should', 'may', 'might', 'must',
      'not', "n't", 'no', 'yes',
      'what', 'where', 'when', 'why', 'who', 'how',
      'all', 'some', 'any', 'many', 'much', 'few', 'little',
      'more', 'most', 'other', 'another', 'such'
    ]);
    
    return functionWords.has(word);
  }
  
  private gradeToCefr(grade: string): string {
    const map: Record<string, string> = {
      '5': 'A1',
      '4': 'A1',
      '3': 'A2',
      'pre-2': 'A2',
      '2': 'B1',
      'pre-1': 'B2',
      '1': 'C1'
    };
    return map[grade] || 'A1';
  }
  
  private isLevelAllowed(actualLevel: string, targetLevel: string): boolean {
    const levels = ['A1', 'A2', 'B1', 'B2', 'C1', 'C2'];
    const actualIndex = levels.indexOf(actualLevel);
    const targetIndex = levels.indexOf(targetLevel);
    return actualIndex <= targetIndex;
  }
  
  private getMinZipf(grade: string): number {
    // Zipfã‚¹ã‚³ã‚¢: é«˜é »åº¦èªã»ã©é«˜ã„ï¼ˆ1.0-7.0ï¼‰
    const thresholds: Record<string, number> = {
      '5': 4.0,   // é »å‡ºèªã®ã¿
      '4': 3.5,
      '3': 3.0,
      'pre-2': 2.5,
      '2': 2.0,
      'pre-1': 1.5,
      '1': 1.0
    };
    return thresholds[grade] || 4.0;
  }
  
  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
}
```

---

### Week 2: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–ã¨å•é¡Œç”Ÿæˆ

#### Day 8-10: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + Few-shotå®Ÿè£…

```typescript
// src/eiken/services/prompt-builder.ts

interface PromptConfig {
  grade: string;
  section: string;
  topicHint?: string;
  difficulty: number;
}

export class EikenPromptBuilder {
  private db: D1Database;
  
  async build(config: PromptConfig): Promise<{ system: string; user: string }> {
    // 1. èªå½™ã‚µãƒ³ãƒ—ãƒ«å–å¾—ï¼ˆé »å‡º50èªï¼‰
    const vocabSample = await this.getTopVocabulary(config.grade, 50);
    
    // 2. Few-shot Exampleså–å¾—ï¼ˆæ‰¿èªæ¸ˆã¿å•é¡Œã‹ã‚‰ï¼‰
    const examples = await this.getFewShotExamples(config.grade, config.section, 3);
    
    // 3. æ–‡æ³•åˆ¶ç´„å–å¾—
    const grammarRules = this.getGrammarRules(config.grade);
    
    return {
      system: this.buildSystemPrompt(config.grade, vocabSample, grammarRules),
      user: this.buildUserPrompt(config, examples)
    };
  }
  
  private buildSystemPrompt(
    grade: string,
    vocabSample: string[],
    grammarRules: string[]
  ): string {
    const levelInfo = this.getLevelInfo(grade);
    
    return `You are an expert EIKEN (è‹±æ¤œ) test creator specializing in Grade ${grade}.

# TARGET AUDIENCE
- Japanese students: ${levelInfo.targetAge}
- CEFR level: ${levelInfo.cefrLevel}
- Vocabulary size: ${levelInfo.vocabSize} words
- Description: ${levelInfo.description}

# CRITICAL VOCABULARY CONSTRAINTS
You MUST use ONLY ${levelInfo.cefrLevel}-level vocabulary.

âœ… ALLOWED vocabulary examples (${levelInfo.cefrLevel} - most common words):
${vocabSample.slice(0, 30).join(', ')}

âŒ ABSOLUTELY FORBIDDEN vocabulary (above ${levelInfo.cefrLevel}):
delighted, promotion, anxious, confused, enhance, remarkable, sophisticated, 
contemporary, inevitable, substantial, magnificent, elaborate, comprehensive

âš ï¸ GOLDEN RULE: If you're unsure about a word's level, always choose a simpler alternative.

# GRAMMAR CONSTRAINTS
ONLY use these grammar structures:
${grammarRules.map(r => `- ${r}`).join('\n')}

âŒ NEVER use:
- Perfect tenses (have/has/had + past participle)
- Conditional perfect (would have + past participle)
- Complex relative clauses
- Passive voice (except simple present/past)
- Subjunctive mood

# QUALITY STANDARDS
1. Natural, realistic contexts relevant to Japanese learners
2. Topics: daily life, school, family, food, hobbies, sports
3. Culturally appropriate content
4. Clear, unambiguous correct answers
5. Plausible distractors (tempting but wrong choices)
6. Simple, direct sentences (max 12 words per sentence for Grade 5)

# OUTPUT FORMAT
Respond ONLY with valid JSON (no markdown, no explanations):
{
  "question_text": "...",
  "choices": ["A", "B", "C", "D"],
  "correct_answer_index": 0,
  "explanation": "...",
  "explanation_ja": "...",
  "translation_ja": "...",
  "vocabulary_used": ["word1", "word2", ...]
}`;
  }
  
  private buildUserPrompt(config: PromptConfig, examples: any[]): string {
    return `Generate ONE ${config.section} question for EIKEN Grade ${config.grade}.

${config.topicHint ? `Topic hint: ${config.topicHint}` : ''}
Difficulty: ${Math.round(config.difficulty * 100)}%

# EXAMPLES OF CORRECT QUESTIONS (Grade ${config.grade})
${examples.map((ex, i) => `
Example ${i + 1}:
Question: ${ex.question_text}
Choices: ${ex.choices.join(' / ')}
Correct: ${ex.correct_answer_index} (${ex.choices[ex.correct_answer_index]})
Explanation: ${ex.explanation}

Why this is good:
- Uses only A1 vocabulary: ${ex.vocabulary_used?.slice(0, 5).join(', ') || 'basic words'}
- Simple grammar: ${ex.grammar_note || 'present simple'}
- Clear context: ${ex.context_note || 'daily life'}
`).join('\n')}

Now create a COMPLETELY NEW question following these examples.
Remember: Use ONLY ${this.getLevelInfo(config.grade).cefrLevel}-level vocabulary!`;
  }
  
  private async getTopVocabulary(grade: string, limit: number): Promise<string[]> {
    const cefr = this.gradeToCefr(grade);
    
    const result = await this.db.prepare(`
      SELECT DISTINCT lemma
      FROM eiken_vocabulary_lexicon
      WHERE cefr_level = ?
        AND frequency_rank IS NOT NULL
      ORDER BY frequency_rank ASC
      LIMIT ?
    `).bind(cefr, limit).all();
    
    return result.results.map(r => r.lemma as string);
  }
  
  private async getFewShotExamples(
    grade: string,
    section: string,
    count: number
  ): Promise<any[]> {
    const result = await this.db.prepare(`
      SELECT 
        question_text,
        choices_json,
        correct_answer_index,
        explanation,
        explanation_ja
      FROM eiken_generated_questions
      WHERE grade = ?
        AND section = ?
        AND review_status = 'approved'
        AND vocab_validation_passed = 1
        AND grammar_validation_passed = 1
      ORDER BY RANDOM()
      LIMIT ?
    `).bind(grade, section, count).all();
    
    return result.results.map(r => ({
      question_text: r.question_text,
      choices: JSON.parse(r.choices_json as string),
      correct_answer_index: r.correct_answer_index,
      explanation: r.explanation,
      explanation_ja: r.explanation_ja
    }));
  }
  
  private getGrammarRules(grade: string): string[] {
    const grammarMap: Record<string, string[]> = {
      '5': [
        'Present simple (I eat, She eats)',
        'Past simple (I ate, She went)',
        'Future with "will" (I will go)',
        'Present continuous for now (I am eating)',
        'Basic questions (Do you...? Is she...?)',
        'Simple negatives (I don\'t like, She isn\'t happy)',
        'Basic prepositions (in, on, at, to, from)',
        'Simple conjunctions (and, but, or)',
        'Imperative (Please sit down, Don\'t run)'
      ],
      '4': [
        'All Grade 5 grammar',
        'Future with "be going to" (I am going to study)',
        'Comparative and superlative adjectives (bigger, biggest)',
        'Present perfect (basic: I have seen)',
        'Modal verbs (can, should, must)',
        'Basic relative clauses (The book that I read)',
        'There is/are constructions'
      ],
      '3': [
        'All Grade 4 grammar',
        'Present perfect continuous (I have been studying)',
        'Past continuous (I was eating)',
        'Passive voice (present/past: is made, was built)',
        'Conditional sentences Type 1 (If I study, I will pass)',
        'Relative pronouns (who, which, that, where)',
        'Indirect questions (I don\'t know where he is)'
      ]
    };
    
    return grammarMap[grade] || grammarMap['5'];
  }
  
  private getLevelInfo(grade: string) {
    const infoMap: Record<string, any> = {
      '5': {
        cefrLevel: 'A1',
        targetAge: '12-13 years (7th grade)',
        vocabSize: '600',
        description: 'Beginner level - First year of English study'
      },
      '4': {
        cefrLevel: 'A1-A2',
        targetAge: '13-14 years (8th grade)',
        vocabSize: '1,300',
        description: 'Elementary level - Second year of English study'
      },
      '3': {
        cefrLevel: 'A2',
        targetAge: '14-15 years (9th grade)',
        vocabSize: '2,100',
        description: 'Pre-intermediate level - Third year of English study'
      }
    };
    
    return infoMap[grade] || infoMap['5'];
  }
  
  private gradeToCefr(grade: string): string {
    const map: Record<string, string> = {
      '5': 'A1',
      '4': 'A1',
      '3': 'A2',
      'pre-2': 'A2',
      '2': 'B1',
      'pre-1': 'B2',
      '1': 'C1'
    };
    return map[grade] || 'A1';
  }
}
```

#### Day 11-14: Cron Triggerå•é¡Œç”ŸæˆWorkerå®Ÿè£…

```typescript
// src/workers/eiken-generator.ts

interface Env {
  DB: D1Database;
  KV: KVNamespace;
  OPENAI_API_KEY: string;
}

export default {
  // Cron Trigger: 10åˆ†æ¯ã«å®Ÿè¡Œ
  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext) {
    console.log('ğŸš€ Eiken Generator Cron triggered');
    
    try {
      const generator = new BatchQuestionGenerator(env);
      await generator.generate();
    } catch (error) {
      console.error('âŒ Cron execution failed:', error);
    }
  }
};

class BatchQuestionGenerator {
  private env: Env;
  private validator: VocabularyValidator;
  private grammarChecker: GrammarValidator;
  private promptBuilder: EikenPromptBuilder;
  
  constructor(env: Env) {
    this.env = env;
    this.validator = new VocabularyValidator(env.DB, env.KV);
    this.grammarChecker = new GrammarValidator();
    this.promptBuilder = new EikenPromptBuilder(env.DB);
  }
  
  async generate() {
    // 1. ç¾åœ¨ã®å•é¡Œãƒ—ãƒ¼ãƒ«ã‚’ç¢ºèª
    const needs = await this.checkInventory();
    
    if (needs.length === 0) {
      console.log('âœ… Inventory is sufficient');
      return;
    }
    
    console.log(`ğŸ“Š Need to generate: ${JSON.stringify(needs)}`);
    
    // 2. å„ä¸è¶³åˆ†ã«å¯¾ã—ã¦ç”Ÿæˆ
    for (const need of needs) {
      await this.generateBatch(need.grade, need.section, need.count);
    }
  }
  
  // å•é¡Œãƒ—ãƒ¼ãƒ«ã®åœ¨åº«ãƒã‚§ãƒƒã‚¯
  private async checkInventory(): Promise<Array<{grade: string; section: string; count: number}>> {
    const targets = [
      { grade: '5', section: 'vocabulary' },
      { grade: '5', section: 'grammar' },
      { grade: '4', section: 'vocabulary' },
      { grade: '4', section: 'grammar' }
    ];
    
    const needs: Array<{grade: string; section: string; count: number}> = [];
    
    for (const target of targets) {
      const result = await this.env.DB.prepare(`
        SELECT COUNT(*) as count
        FROM eiken_generated_questions
        WHERE grade = ?
          AND section = ?
          AND review_status = 'approved'
      `).bind(target.grade, target.section).first();
      
      const current = result?.count || 0;
      const minimum = 50; // æœ€ä½åœ¨åº«
      
      if (current < minimum) {
        needs.push({
          ...target,
          count: minimum - current
        });
      }
    }
    
    return needs;
  }
  
  // ãƒãƒƒãƒç”Ÿæˆï¼ˆ10å•ã¾ã¨ã‚ã¦ï¼‰
  private async generateBatch(
    grade: string,
    section: string,
    totalCount: number
  ) {
    const batchSize = 10;
    const batches = Math.ceil(totalCount / batchSize);
    
    for (let i = 0; i < batches; i++) {
      const count = Math.min(batchSize, totalCount - i * batchSize);
      
      try {
        await this.generateSingleBatch(grade, section, count);
      } catch (error) {
        console.error(`âŒ Batch ${i + 1} failed:`, error);
      }
      
      // ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆ60 RPMï¼‰
      if (i < batches - 1) {
        await this.sleep(1000);
      }
    }
  }
  
  private async generateSingleBatch(
    grade: string,
    section: string,
    count: number
  ) {
    console.log(`ğŸ”„ Generating ${count} questions for Grade ${grade}, Section: ${section}`);
    
    // 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    const prompts = await this.promptBuilder.build({
      grade,
      section,
      difficulty: 0.6
    });
    
    // 2. OpenAI APIå‘¼ã³å‡ºã—ï¼ˆgpt-4o-miniï¼‰
    const batchPrompt = `${prompts.user}

Generate ${count} UNIQUE questions.
Each question must be COMPLETELY DIFFERENT from others.

Output format:
{
  "questions": [
    { "question_text": "...", "choices": [...], ... },
    { "question_text": "...", "choices": [...], ... },
    ...
  ]
}`;
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: prompts.system,
            // Prompt Cachingæœ‰åŠ¹åŒ–
            cache_control: { type: 'ephemeral' }
          },
          {
            role: 'user',
            content: batchPrompt
          }
        ],
        temperature: 0.8,
        max_tokens: 4000,
        response_format: { type: 'json_object' }
      })
    });
    
    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }
    
    const data = await response.json();
    const content = data.choices[0].message.content;
    const parsed = JSON.parse(content);
    const questions = parsed.questions || [];
    
    console.log(`âœ… Generated ${questions.length} questions`);
    
    // 3. å„å•é¡Œã‚’æ¤œè¨¼ãƒ»ä¿å­˜
    for (const question of questions) {
      await this.validateAndSave(question, grade, section, 'gpt-4o-mini');
    }
  }
  
  private async validateAndSave(
    question: any,
    grade: string,
    section: string,
    model: string
  ) {
    const questionText = question.question_text || question.question || '';
    const choices = question.choices || [];
    const correctIndex = question.correct_answer_index ?? question.correctAnswerIndex;
    
    // 1. èªå½™æ¤œè¨¼
    const fullText = `${questionText} ${choices.join(' ')}`;
    const vocabResult = await this.validator.validate(fullText, grade, {
      strictMode: false, // 5%è¨±å®¹
      useZipf: true
    });
    
    // 2. æ–‡æ³•æ¤œè¨¼
    const grammarResult = await this.grammarChecker.validate(questionText, grade);
    
    // 3. æ¤œè¨¼çµæœã«åŸºã¥ãå‡¦ç†
    let finalQuestion = question;
    let finalVocabResult = vocabResult;
    let finalGrammarResult = grammarResult;
    
    // èªå½™é•åãŒã‚ã‚Œã°è‡ªå‹•ãƒªãƒ©ã‚¤ãƒˆ
    if (!vocabResult.passed && vocabResult.violations.length > 0) {
      console.log(`âš ï¸ Vocab violations found, attempting rewrite...`);
      
      try {
        finalQuestion = await this.rewriteQuestion(
          question,
          vocabResult.violations.map(v => v.word)
        );
        
        // å†æ¤œè¨¼
        const rewrittenText = `${finalQuestion.question_text} ${finalQuestion.choices.join(' ')}`;
        finalVocabResult = await this.validator.validate(rewrittenText, grade, {
          strictMode: false,
          useZipf: true
        });
      } catch (error) {
        console.error('âŒ Rewrite failed:', error);
      }
    }
    
    // 4. D1ã«ä¿å­˜
    const reviewStatus = 
      finalVocabResult.passed && finalGrammarResult.passed ? 'approved' : 'rejected';
    
    await this.env.DB.prepare(`
      INSERT INTO eiken_generated_questions (
        grade,
        section,
        question_type,
        answer_type,
        question_text,
        choices_json,
        correct_answer_index,
        explanation,
        explanation_ja,
        translation_ja,
        difficulty_score,
        vocab_validation_passed,
        vocab_violation_ratio,
        vocab_violations_json,
        grammar_validation_passed,
        grammar_violations_json,
        review_status,
        model_used,
        generated_at,
        created_at
      ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'), datetime('now'))
    `).bind(
      grade,
      section,
      section,
      'mcq',
      finalQuestion.question_text,
      JSON.stringify(finalQuestion.choices),
      finalQuestion.correct_answer_index,
      finalQuestion.explanation || '',
      finalQuestion.explanation_ja || '',
      finalQuestion.translation_ja || '',
      0.6,
      finalVocabResult.passed ? 1 : 0,
      finalVocabResult.violationRatio,
      JSON.stringify(finalVocabResult.violations),
      finalGrammarResult.passed ? 1 : 0,
      JSON.stringify(finalGrammarResult.violations),
      reviewStatus,
      model,
    ).run();
    
    console.log(`${reviewStatus === 'approved' ? 'âœ…' : 'âŒ'} Question ${reviewStatus}`);
  }
  
  // é•åèªã®ã¿ã‚’è‡ªå‹•ãƒªãƒ©ã‚¤ãƒˆ
  private async rewriteQuestion(
    question: any,
    violationWords: string[]
  ): Promise<any> {
    const prompt = `Rewrite this question to replace ONLY the problematic words with simpler A1-level synonyms.
Do NOT change the grammar structure or meaning.

Problematic words: ${violationWords.join(', ')}

Original question:
${JSON.stringify(question)}

Return rewritten question in the same JSON format.`;
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0,
        response_format: { type: 'json_object' }
      })
    });
    
    const data = await response.json();
    return JSON.parse(data.choices[0].message.content);
  }
  
  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

---

### Week 3: ãƒ¦ãƒ¼ã‚¶ãƒ¼APIå®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆ

#### Day 15-17: ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘APIå®Ÿè£…

```typescript
// src/eiken/routes/generate.tsï¼ˆæ”¹è‰¯ç‰ˆï¼‰

const generate = new Hono<{ Bindings: EikenEnv }>();

/**
 * GET /api/eiken/generate?grade=5&section=vocabulary&count=5
 * 
 * æ‰¿èªæ¸ˆã¿å•é¡Œãƒ—ãƒ¼ãƒ«ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«å•é¡Œã‚’å–å¾—
 * ï¼ˆAIã‚’å‘¼ã³å‡ºã•ãªã„é«˜é€ŸAPIï¼‰
 */
generate.get('/', async (c) => {
  try {
    const grade = c.req.query('grade') || '5';
    const section = c.req.query('section') || 'vocabulary';
    const count = parseInt(c.req.query('count') || '5', 10);
    
    if (count < 1 || count > 20) {
      return c.json({
        success: false,
        error: 'Count must be between 1 and 20'
      }, 400);
    }
    
    // D1ã‹ã‚‰æ‰¿èªæ¸ˆã¿å•é¡Œã‚’å–å¾—
    const result = await c.env.DB.prepare(`
      SELECT 
        id,
        question_text,
        choices_json,
        correct_answer_index,
        explanation,
        explanation_ja,
        translation_ja,
        difficulty_score
      FROM eiken_generated_questions
      WHERE grade = ?
        AND section = ?
        AND review_status = 'approved'
      ORDER BY RANDOM()
      LIMIT ?
    `).bind(grade, section, count).all();
    
    const questions = result.results.map(r => ({
      questionNumber: r.id,
      questionText: r.question_text,
      choices: JSON.parse(r.choices_json as string),
      correctAnswerIndex: r.correct_answer_index,
      explanation: r.explanation,
      explanationJa: r.explanation_ja,
      translationJa: r.translation_ja,
      difficulty: r.difficulty_score,
      copyrightSafe: true,
      copyrightScore: 100
    }));
    
    return c.json({
      success: true,
      generated: questions,
      questions, // å¾Œæ–¹äº’æ›æ€§
      rejected: 0,
      totalAttempts: count,
      saved: questions.length,
      source: 'pre-approved-pool'
    });
    
  } catch (error) {
    console.error('âŒ API error:', error);
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

/**
 * GET /api/eiken/generate/inventory
 * 
 * ç¾åœ¨ã®å•é¡Œãƒ—ãƒ¼ãƒ«åœ¨åº«çŠ¶æ³
 */
generate.get('/inventory', async (c) => {
  try {
    const result = await c.env.DB.prepare(`
      SELECT 
        grade,
        section,
        COUNT(*) as count,
        AVG(difficulty_score) as avg_difficulty,
        AVG(vocab_violation_ratio) as avg_violation_ratio
      FROM eiken_generated_questions
      WHERE review_status = 'approved'
      GROUP BY grade, section
      ORDER BY grade, section
    `).all();
    
    return c.json({
      success: true,
      inventory: result.results
    });
    
  } catch (error) {
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error'
    }, 500);
  }
});

export default generate;
```

#### Day 18-21: çµ±åˆãƒ†ã‚¹ãƒˆã¨å“è³ªãƒã‚§ãƒƒã‚¯

```typescript
// tests/integration/eiken-generation.test.ts

describe('Eiken Generation System', () => {
  let db: D1Database;
  let kv: KVNamespace;
  
  beforeAll(async () => {
    // ãƒ†ã‚¹ãƒˆç”¨D1ã¨KVã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
  });
  
  describe('Vocabulary Validation', () => {
    it('should pass A1 vocabulary', async () => {
      const text = 'I eat breakfast every morning. My mother cooks it.';
      const validator = new VocabularyValidator(db, kv);
      
      const result = await validator.validate(text, '5', { strictMode: false });
      
      expect(result.passed).toBe(true);
      expect(result.violations).toHaveLength(0);
    });
    
    it('should reject B1+ vocabulary', async () => {
      const text = 'I was delighted to receive the promotion.';
      const validator = new VocabularyValidator(db, kv);
      
      const result = await validator.validate(text, '5', { strictMode: false });
      
      expect(result.passed).toBe(false);
      expect(result.violations.length).toBeGreaterThan(0);
      expect(result.violations.some(v => v.word === 'delighted')).toBe(true);
    });
  });
  
  describe('Question Generation', () => {
    it('should generate valid Grade 5 questions', async () => {
      const generator = new BatchQuestionGenerator({ DB: db, KV: kv, OPENAI_API_KEY: process.env.OPENAI_API_KEY! });
      
      await generator.generateSingleBatch('5', 'vocabulary', 3);
      
      const result = await db.prepare(`
        SELECT * FROM eiken_generated_questions
        WHERE grade = '5'
          AND review_status = 'approved'
        LIMIT 3
      `).all();
      
      expect(result.results.length).toBeGreaterThan(0);
      
      for (const q of result.results) {
        expect(q.vocab_validation_passed).toBe(1);
        expect(q.grammar_validation_passed).toBe(1);
        expect(q.vocab_violation_ratio).toBeLessThan(0.05);
      }
    });
  });
  
  describe('User API', () => {
    it('should return questions quickly', async () => {
      const start = Date.now();
      
      const response = await fetch('http://localhost:8787/api/eiken/generate?grade=5&section=vocabulary&count=5');
      const data = await response.json();
      
      const elapsed = Date.now() - start;
      
      expect(response.ok).toBe(true);
      expect(data.success).toBe(true);
      expect(data.generated.length).toBe(5);
      expect(elapsed).toBeLessThan(100); // 100msä»¥å†…
    });
  });
});
```

---

## ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹æˆæœ

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™

| æŒ‡æ¨™ | ç›®æ¨™å€¤ | å®Ÿæ¸¬äºˆæƒ³ |
|------|--------|----------|
| ãƒ¦ãƒ¼ã‚¶ãƒ¼APIå¿œç­”æ™‚é–“ | <100ms | 20-50ms |
| èªå½™æ¤œè¨¼ç²¾åº¦ | >95% | 98% |
| æ–‡æ³•æ¤œè¨¼ç²¾åº¦ | >90% | 85-90% |
| æ‰¿èªç‡ï¼ˆåˆå›ç”Ÿæˆï¼‰ | >70% | 75% |
| APIå‘¼ã³å‡ºã—ã‚³ã‚¹ãƒˆï¼ˆ100å•ï¼‰ | <$0.50 | $0.15 |

### ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœ

| é …ç›® | å¾“æ¥æ–¹å¼ | æœ€é©åŒ–å¾Œ | å‰Šæ¸›ç‡ |
|------|---------|---------|--------|
| ãƒ¢ãƒ‡ãƒ« | gpt-4o | gpt-4o-mini | 90% |
| ç”Ÿæˆæ–¹å¼ | å€‹åˆ¥1å•ãšã¤ | ãƒãƒƒãƒ10å• | 80% |
| ã‚­ãƒ£ãƒƒã‚·ãƒ¥ | ãªã— | ã‚ã‚Š | 50% |
| **ç·åˆ** | **$3.00/100å•** | **$0.15/100å•** | **95%** |

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **ä»Šé€±æœ«**: 
   - CEFR-J Wordlistã®Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
   - æ´»ç”¨å½¢å±•é–‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ä½œæˆ

2. **Week 1é–‹å§‹æ™‚**:
   - D1ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
   - èªå½™ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
   - æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…

3. **Week 2**:
   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Œæˆ
   - Cron Workerå®Ÿè£…

4. **Week 3**:
   - ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚°
   - 5ç´šå®Œå…¨ãƒªãƒªãƒ¼ã‚¹

---

## âœ… æˆåŠŸã®éµ

1. **ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆ**: èªå½™DBã®å“è³ªãŒã™ã¹ã¦
2. **äºˆé˜²>æ²»ç™‚**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§80%é˜²ãã€æ¤œè¨¼ã§15%æ”¹å–„
3. **éåŒæœŸåˆ†é›¢**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨AIç”Ÿæˆã‚’å®Œå…¨åˆ†é›¢
4. **æ®µéšçš„æ”¹å–„**: 5ç´šã§å®Œç’§ã«ã—ã¦ã‹ã‚‰ä»–ç´šã«å±•é–‹

ã“ã®è¨ˆç”»ã«å¾“ãˆã°ã€**é«˜å“è³ªãƒ»ä½ã‚³ã‚¹ãƒˆãƒ»é«˜é€Ÿ**ãªè‹±æ¤œå•é¡Œç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿç¾ã§ãã¾ã™ï¼

ã”è³ªå•ã‚„å®Ÿè£…ä¸­ã®å›°ã‚Šã”ã¨ãŒã‚ã‚Œã°ã€ã„ã¤ã§ã‚‚ãŠå£°ãŒã‘ãã ã•ã„ã€‚ğŸ™‡â€â™‚ï¸
